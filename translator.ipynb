{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UkBK22_OIaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.0.0-beta1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQPKpLN8fXkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCxP5sJYfXsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uBRNyAifYLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uSR1aSunR8I",
        "colab_type": "code",
        "outputId": "72f65f45-8fd6-41dd-e35a-3b2ec54195ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlu9a8aDULdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import io\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n43svl3m5T0T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/gdrive/My Drive/train_english.en','r') as f:\n",
        "  english_data = f.read().split('\\n')\n",
        "with open('/content/gdrive/My Drive/train_hindi.hi','r') as f:\n",
        "  hindi_data_ = f.read().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFTREwFR5UWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/gdrive/My Drive/english_to_hindi/test/dev_english.en','r') as f:\n",
        "  english_data_dev = f.read().split('\\n')\n",
        "with open('/content/gdrive/My Drive/english_to_hindi/test/dev_hindi.hi','r') as f:\n",
        "  hindi_data_dev_ = f.read().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elLFNQY5sWvV",
        "colab_type": "code",
        "outputId": "dd0e57f7-3bb2-4f14-98fc-8394f1180eb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "english_data = english_data[:100000]\n",
        "hindi_data_ = hindi_data_[:100000]\n",
        "print(len(english_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0N5eIpgTctpO",
        "colab_type": "code",
        "outputId": "80d1deb3-5fff-44af-c7c4-d34e65e33f5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(english_data[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Give your application an accessibility workout\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oviPlBQypgK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "english_data_processed = []\n",
        "for line in english_data:\n",
        "  english_data_processed.append(line.lower())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ubHPnY4712Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def tokenizing_english(english_data):\n",
        "#   tokenizer = keras.preprocessing.text.Tokenizer()\n",
        "#   tokenizer.fit_on_texts(english_data)\n",
        "#   english_seq = tokenizer.texts_to_sequences(english_data)\n",
        "#   length_list = []\n",
        "#   for seq in english_seq:\n",
        "#     length_list.append(len(seq))\n",
        "#   max_eng_len = np.array(length_list).max()\n",
        "\n",
        "#   english_words = tokenizer.word_index\n",
        "#   num_english_words = len(english_words) + 1\n",
        "#   padded_english = keras.preprocessing.sequence.pad_sequences(english_seq,maxlen = max_eng_len,padding = 'post')\n",
        "#   padded_english = np.array(padded_english)\n",
        "\n",
        "#   return max_eng_len,num_english_words,english_words,padded_english\n",
        "# num_english_words,"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgBhvaNy715e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def tokenizing_hindi(hindi_data_):\n",
        "#   tokenizer = keras.preprocessing.text.Tokenizer()\n",
        "#   hindi_data = []\n",
        "#   for line in hindi_data_:\n",
        "#     hindi_data.append('<start>' + line + '<end>')\n",
        "#   tokenizer.fit_on_texts(hindi_data)\n",
        "#   hindi_seq = tokenizer.texts_to_sequences(hindi_data)\n",
        "\n",
        "#   for seq in hindi_seq:\n",
        "#     length_list.append(len(seq))\n",
        "#   max_hin_len = np.array(length_list).max()\n",
        "\n",
        "#   hindi_words = tokenizer.word_index\n",
        "#   num_hindi_words = len(hindi_words) + 1\n",
        "#   padded_hindi = keras.preprocessing.sequence.pad_sequences(hindi_seq,maxlen = max_hin_len,padding = 'post')\n",
        "#   padded_hindi = np.array(padded_hindi)\n",
        "\n",
        "#   output_data = []\n",
        "#   for token_seq in hindi_seq:\n",
        "#     output_data.append(token_seq[1:])\n",
        "\n",
        "#   padded_hindi_output = keras.preprocessing.sequence.pad_sequences(output_data,maxlen =max_hin_len,padding = 'post')\n",
        "#   output_hindi = keras.utils.to_categorical(padded_hindi_output,num_hindi_words)\n",
        "#   output_hindi = np.array(output_hindi)\n",
        "\n",
        "#   return max_hin_len,num_hindi_words,hindi_words,padded_hindi,output_hindi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CwQM3In-lru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# j = 0\n",
        "# for i in range(10000,len(english_data_processed),10000):\n",
        "#   english_data_temp = english_data[j:i]\n",
        "#   hindi_data_temp = hindi_data[j:i]\n",
        "#   max_eng_len,num_english_words,english_words,padded_english\n",
        "\n",
        "#   j = i "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUZkM4lkpioR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(english_data_processed)\n",
        "english_seq = tokenizer.texts_to_sequences(english_data_processed)\n",
        "\n",
        "length_list_english = []\n",
        "\n",
        "for seq in english_seq:\n",
        "  length_list_english.append(len(seq))\n",
        "max_eng_len = np.array(length_list_english).max()\n",
        "max_eng_len = 50\n",
        "english_words = tokenizer.word_index\n",
        "num_english_words = len(english_words) + 1\n",
        "padded_english = keras.preprocessing.sequence.pad_sequences(english_seq,maxlen = max_eng_len,padding = 'post')\n",
        "padded_english = np.array(padded_english)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkq_HXjlOaOx",
        "colab_type": "code",
        "outputId": "8f9befc1-3109-462a-a37d-3dbcae349df9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(num_english_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vD9w7XDIv4C",
        "colab_type": "code",
        "outputId": "c078476a-b10d-436b-a50f-cd4d6e8405ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(padded_english.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100000, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qkfw8mrcuIFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = keras.preprocessing.text.Tokenizer()\n",
        "hindi_data = []\n",
        "for line in hindi_data_:\n",
        "  hindi_data.append('<start>' + line + '<end>')\n",
        "tokenizer.fit_on_texts(hindi_data)\n",
        "hindi_seq = tokenizer.texts_to_sequences(hindi_data)\n",
        "\n",
        "length_list_hindi = []\n",
        "\n",
        "for seq in hindi_seq:\n",
        "  length_list_hindi.append(len(seq))\n",
        "max_hin_len = np.array(length_list_hindi).max()\n",
        "max_hin_len = 50\n",
        "hindi_words = tokenizer.word_index\n",
        "num_hindi_words = len(hindi_words) + 1\n",
        "padded_hindi = keras.preprocessing.sequence.pad_sequences(hindi_seq,maxlen = max_hin_len,padding = 'post')\n",
        "padded_hindi = np.array(padded_hindi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd7Ka1d8NfYV",
        "colab_type": "code",
        "outputId": "8e43e335-988b-47dd-c730-63d4afca32c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "length_list = []\n",
        "print(padded_hindi.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100000, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2KBpbQia1_g",
        "colab_type": "code",
        "outputId": "7752cff6-b451-461b-83ee-b62735e5daa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "i = 0\n",
        "j = 0\n",
        "for l in length_list_english:\n",
        "  if (l > 50):\n",
        "    i = i + 1\n",
        "for l in length_list_hindi:\n",
        "  if (l > 50):\n",
        "    j = j + 1\n",
        "\n",
        "print(max_hin_len)\n",
        "print(i,j)\n",
        "print(len(length_list_english))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50\n",
            "118 167\n",
            "100000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hch2rwQYQYi8",
        "colab_type": "code",
        "outputId": "35a02cea-a4ce-4f80-8fd3-6230369c2a42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(num_hindi_words)\n",
        "output_data = []\n",
        "for token_seq in hindi_seq:\n",
        "  output_data.append(token_seq[1:])\n",
        "\n",
        "padded_hindi_output = keras.preprocessing.sequence.pad_sequences(output_data,maxlen =max_hin_len,padding = 'post')\n",
        "print(len(padded_hindi_output))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8555\n",
            "100000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZE6dVd2WtdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feZo8Yc3Wtgo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(padded_hindi_output[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG8vpFCVT5kU",
        "colab_type": "code",
        "outputId": "196c7e55-26bb-42a9-edf0-997639ca1d0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "j = 0\n",
        "i = 10000\n",
        "padded_english_temp = padded_english[j:i]\n",
        "padded_hindi_temp = padded_hindi[j:i]\n",
        "padded_hindi_output_temp = padded_hindi_output[j:i]\n",
        "print(num_hindi_words)\n",
        "print(len(padded_hindi_output_temp))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8555\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7c-vGfsUEqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "output_hindi = keras.utils.to_categorical(padded_hindi_output_temp,num_hindi_words,dtype = 'uint8')\n",
        "output_hindi = np.array(output_hindi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzEuqp2hUEt1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jxzyb0GNUExR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qlxmThVSZFg",
        "colab_type": "code",
        "outputId": "21284639-3e59-4d20-f1a5-c36a3e9b9044",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# ENCODER\n",
        "encoder_inputs = keras.layers.Input(shape = (None,))\n",
        "encoder_embedding = keras.layers.Embedding(num_english_words,256,mask_zero = True)(encoder_inputs)\n",
        "encoder_lstm1 = keras.layers.LSTM(128,return_sequences=True)(encoder_embedding)\n",
        "encoder_output,state_h,state_c = keras.layers.LSTM(128,return_state=True)(encoder_lstm1)\n",
        "encoder_states = [state_h,state_c]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:3868: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq9ThhqSSZ9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DECODER\n",
        "decoder_inputs = keras.layers.Input(shape = (None,))\n",
        "decoder_embedding = keras.layers.Embedding(num_hindi_words,256,mask_zero = True)(decoder_inputs)\n",
        "decoder_lstm1 = keras.layers.LSTM(128,return_state=True,return_sequences=True)\n",
        "decoder_output,_,_ = decoder_lstm1(decoder_embedding,initial_state = encoder_states)\n",
        "decoder_dense = keras.layers.Dense(num_hindi_words,activation='softmax')\n",
        "output = decoder_dense(decoder_output)\n",
        "\n",
        "model = keras.models.Model([encoder_inputs,decoder_inputs],output)\n",
        "model.compile(optimizer = keras.optimizers.RMSprop(),loss = 'categorical_crossentropy',metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDQBANJaad9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fqpqyamQigo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "j = 0\n",
        "for i in range(5000,len(padded_hindi_output),5000):\n",
        "  padded_english_temp = padded_english[j:i]\n",
        "  padded_hindi_temp = padded_hindi[j:i]\n",
        "  padded_hindi_output_temp = padded_hindi_output[j:i]\n",
        "  output_hindi = keras.utils.to_categorical(padded_hindi_output_temp,num_hindi_words,dtype = 'uint8')\n",
        "  output_hindi = np.array(output_hindi)\n",
        "\n",
        "  model.fit([padded_english_temp,padded_hindi_temp],output_hindi,epochs = 10)\n",
        "\n",
        "  model.save('model.h5')\n",
        "  j = i \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UOCpm2EuLqP",
        "colab_type": "code",
        "outputId": "7487d54a-288c-4dfe-a25f-5ff869f8ce55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "210417\n",
            "1000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4oG0w3xvOyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PXoej4gvWpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_WK3I317m6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.fit([padded_english,padded_hindi],output_hindi,batch_size = 100,epochs = 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGWKZ4DU9po8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_inference_models():\n",
        "  encoder_model = keras.models.Model(encoder_inputs,encoder_states)\n",
        "\n",
        "  decoder_state_h = keras.layers.Input(shape=(128,))\n",
        "  decoder_state_c = keras.layers.Input(shape=(128,))\n",
        "\n",
        "  decoder_states_in = [decoder_state_h,decoder_state_c]\n",
        "\n",
        "  decoder_outputs,state_h,state_c = decoder_lstm1(decoder_embedding,initial_state=decoder_states_in)\n",
        "  decoder_states = [state_h,state_c]\n",
        "  decoder_outputs = decoder_dense(decoder_outputs)\n",
        "  decoder_model = keras.models.Model(\n",
        "      [decoder_inputs] + decoder_states_in,[decoder_outputs] +decoder_states\n",
        "  )\n",
        "  return encoder_model,decoder_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyBjucQUPXxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def str_to_tokens(sentence : str):\n",
        "  words = sentence.lower().split()\n",
        "  tokens_list = []\n",
        "  for word in words:\n",
        "    tokens_list.append(english_words[word])\n",
        "  return keras.preprocessing.sequence.pad_sequences([tokens_list],maxlen=max_eng_len,padding='post')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXYOHN7cf6SG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bysrOlG7Q8-_",
        "colab_type": "code",
        "outputId": "f844ffec-43d2-429f-cd20-f176bd856b5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "enc_model ,dec_model = make_inference_models()\n",
        "goody = 'No one was injured in the accident'\n",
        "for epoch in range(1):\n",
        "  states_values = enc_model.predict(str_to_tokens(goody))\n",
        "  empty_target_sequence = np.zeros((1,1))\n",
        "  empty_target_sequence[0,0] = hindi_words['start']\n",
        "  stop_condition = False\n",
        "  decoded_translation = ''\n",
        "\n",
        "  while not stop_condition:\n",
        "    dec_outputs, h ,c= dec_model.predict([empty_target_sequence] + states_values)\n",
        "    sampled_word_index = np.argmax(dec_outputs[0,-1,:])\n",
        "    sampled_word = None\n",
        "    for word,index in hindi_words.items():\n",
        "      if sampled_word_index == index:\n",
        "        decoded_translation += '{}'.format(word)\n",
        "        decoded_translation += ' '\n",
        "        sampled_word = word\n",
        "    if sampled_word == 'end' or len(decoded_translation.split()) > num_hindi_words:\n",
        "      stop_condition = True\n",
        "    empty_target_sequence = np.zeros((1,1))\n",
        "    empty_target_sequence[0,0] = sampled_word_index\n",
        "    states_values = [h,c]\n",
        "  print(decoded_translation)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "हादसे में किसी को भी चोट नहीं आई। end \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPOH8QEAT1gu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtQbItMfWGVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}